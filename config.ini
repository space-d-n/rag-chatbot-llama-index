[logging]
debug=TRUE

[llm]
model_location=<path-to-model>/llama-2-7b-chat/ggml-model-q4_0.gguf
# chosen based on MTEB leaderboard (https://huggingface.co/spaces/mteb/leaderboard) considering small size of the dataset
embedding_model_name=BAAI/bge-small-en-v1.5
documents_location=<path-to-documents-for-embedding>
# getting tokenizer from this repo on HuggingFace
model_path_hf=meta-llama/Llama-2-7b-chat-hf
# Hugging Face API token
api_token_hf=<hf-token>
# default context prompt is inside llama-index lib
context_prompt_file=<path-to-custom-context-prompt>
