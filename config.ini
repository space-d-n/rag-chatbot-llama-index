[logging]
debug=TRUE

[llm]
model_location=<path-to-model>/llama-2-13b-chat.Q4_0.gguf
# chosen based on MTEB leaderboard (https://huggingface.co/spaces/mteb/leaderboard) considering small size of the dataset
embedding_model_name=BAAI/bge-small-en-v1.5
documents_location=./simplex-chat-docs
# getting tokenizer from this repo on HuggingFace
model_path_hf=meta-llama/Llama-2-13b-chat-hf
# Hugging Face API token
api_token_hf=<hugging-face-api-token>
# default context prompt is inside llama-index lib
context_prompt_file=./context_prompt_v4.txt
